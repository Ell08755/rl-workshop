{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.special import softmax \n",
    "import time \n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from utils.env import frozen_lake\n",
    "from utils.viz import viz \n",
    "viz.get_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234 \n",
    "env = frozen_lake(seed=seed)\n",
    "env.reset()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "env.render(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "acts = [3, 3, 3, 1, 1, 1]\n",
    "for a in acts:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    clear_output(True)\n",
    "    env.render(ax)\n",
    "    plt.show()\n",
    "    if done: break\n",
    "    _, _, done =env.step(a)\n",
    "    time.sleep(.1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the environment \n",
    "\n",
    "Actions: \n",
    "\n",
    "* 0: up\n",
    "* 1: down\n",
    "* 2: left\n",
    "* 3: right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check transition function\n",
    "# check p_trans of a surface\n",
    "env.p_s_next(s=1, a=2).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check p trans of a hole\n",
    "env.p_s_next(s=19, a=2).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check reward function of a surface, hole, and goal \n",
    "env.r(2), env.r(19), env.r(63), "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random policy \n",
    "rng = np.random.RandomState(1234)\n",
    "pi_rand = softmax(rng.rand(env.nS, env.nA)*5, axis=1)\n",
    "pi_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(pi, env, theta=1e-4, gamma=.99):\n",
    "\n",
    "    # initialize V(s), arbitrarily except V(terminal)=0\n",
    "    ##################################\n",
    "    #         Your Answer            #\n",
    "    ##################################\n",
    "    # except v(terminal) = 0\n",
    "    for s in env.s_termination:\n",
    "        pass\n",
    "        ##################################\n",
    "        #         Your Answer            #\n",
    "        ##################################\n",
    "\n",
    "    # loop until convergence\n",
    "    while True: \n",
    "        delta = 0\n",
    "        for s in env.S:\n",
    "            if s not in env.s_termination:\n",
    "                v_old = V[s].copy()\n",
    "                v_new = 0\n",
    "                for a in env.A:\n",
    "                    p = env.p_s_next(s, a)\n",
    "                    for s_next in env.S:\n",
    "                        ##################################\n",
    "                        #         Your Answer            #\n",
    "                        ##################################\n",
    "                       pass\n",
    "                V[s] = v_new \n",
    "                # check convergence\n",
    "                ##################################\n",
    "                #         Your Answer            #\n",
    "                ##################################\n",
    "        \n",
    "        if delta < theta:\n",
    "            break \n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improve(pi, V, env, theta=1e-4, gamma=.99):\n",
    "    pi_old = pi.copy()\n",
    "    for s in env.S:\n",
    "        q = np.zeros([env.nA])\n",
    "        for a in env.A:\n",
    "            for s_next in env.S:\n",
    "                ##################################\n",
    "                #         Your Answer            #\n",
    "                ##################################\n",
    "        # get new policy \n",
    "        ##################################\n",
    "        #         Your Answer            #\n",
    "        ##################################\n",
    "    \n",
    "    # check stable\n",
    "    ##################################\n",
    "    #         Your Answer            #\n",
    "    ##################################\n",
    "\n",
    "    return pi, stable  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iter(env, seed=1234):\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # initialize V(s), arbitrarily except V(terminal)=0\n",
    "    V = rng.rand(env.nS) * 0.001\n",
    "    # except v(terminal) = 0\n",
    "    for s in env.s_termination:\n",
    "        V[s] = 0\n",
    "    # initialize Ï€(s), arbitrarily\n",
    "    pi = softmax(rng.rand(env.nS, env.nA)*5, axis=1)\n",
    "\n",
    "    while True: \n",
    "\n",
    "        V = policy_eval(pi, V, env)\n",
    "        pi, stable = policy_improve(pi, V, env)\n",
    "        if stable: break \n",
    "\n",
    "    return V, pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1, pi1 = policy_iter(env)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axs[0]\n",
    "env.show_v(ax, V1)\n",
    "ax = axs[1]\n",
    "env.show_pi(ax, pi1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iter(env, seed=1234, theta=1e-4, gamma=.99):\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    # initialize V(s), arbitrarily except V(terminal)=0\n",
    "    ##################################\n",
    "    #         Your Answer            #\n",
    "    ##################################\n",
    "    # init policy \n",
    "    ##################################\n",
    "    #         Your Answer            #\n",
    "    ##################################\n",
    "    # loop until converge\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in env.S:\n",
    "            v_old = V[s].copy()\n",
    "            for a in env.A:\n",
    "                for s_next in env.S:\n",
    "                    ##################################\n",
    "                    #         Your Answer            #\n",
    "                    ##################################\n",
    "            # calculate V\n",
    "            ##################################\n",
    "            #         Your Answer            #\n",
    "            ##################################\n",
    "            # get new policy \n",
    "            ##################################\n",
    "            #         Your Answer            #\n",
    "            ##################################\n",
    "            delta = np.max([delta, np.abs(V[s] - v_old)])\n",
    "\n",
    "        if delta < theta:\n",
    "            break \n",
    "    for s in env.s_termination:\n",
    "        V[s] = 0\n",
    "    return V, pi \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V2, pi2 = value_iter(env)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axs[0]\n",
    "env.show_v(ax, V2)\n",
    "ax = axs[1]\n",
    "env.show_pi(ax, pi2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q learning, TD learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning(env, alpha=.05, eps=.1, gamma=.99, max_epi=100, seed=1234, theta=1e-4):\n",
    "    # rng\n",
    "    rng = np.random.RandomState(seed)\n",
    "    # initialize Q\n",
    "    Q = np.zeros([env.nS, env.nA])\n",
    "    for _ in range(max_epi):\n",
    "        s, r, done = env.reset()\n",
    "        t = 0 \n",
    "        q_old = Q.copy()\n",
    "        while True:\n",
    "            # sample At, observe Rt, St+1\n",
    "            ##################################\n",
    "            #         Your Answer            #\n",
    "            ##################################\n",
    "            t += 1\n",
    "            if done:\n",
    "                break \n",
    "        if (np.abs(q_old - Q)<theta).all():\n",
    "            break\n",
    "    pi = np.eye(env.nA)[np.argmax(Q, axis=1)]\n",
    "    return Q, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, pi3 = Q_learning(env)\n",
    "V3 = Q.max(1)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axs[0]\n",
    "env.show_v(ax, V3)\n",
    "ax = axs[1]\n",
    "env.show_pi(ax, pi3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
